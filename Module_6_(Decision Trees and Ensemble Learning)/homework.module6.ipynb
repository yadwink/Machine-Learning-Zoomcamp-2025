{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6df8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f026829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   engine_displacement  num_cylinders  horsepower  vehicle_weight  \\\n",
      "0                  170            3.0       159.0     3413.433759   \n",
      "1                  130            5.0        97.0     3149.664934   \n",
      "2                  170            NaN        78.0     3079.038997   \n",
      "3                  220            4.0         NaN     2542.392402   \n",
      "4                  210            1.0       140.0     3460.870990   \n",
      "\n",
      "   acceleration  model_year  origin fuel_type         drivetrain  num_doors  \\\n",
      "0          17.7        2003  Europe  Gasoline    All-wheel drive        0.0   \n",
      "1          17.8        2007     USA  Gasoline  Front-wheel drive        0.0   \n",
      "2          15.1        2018  Europe  Gasoline  Front-wheel drive        0.0   \n",
      "3          20.2        2009     USA    Diesel    All-wheel drive        2.0   \n",
      "4          14.4        2009  Europe  Gasoline    All-wheel drive        2.0   \n",
      "\n",
      "   fuel_efficiency_mpg  \n",
      "0            13.231729  \n",
      "1            13.688217  \n",
      "2            14.246341  \n",
      "3            16.912736  \n",
      "4            12.488369  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"car_fuel_efficiency.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a677cb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "engine_displacement      0\n",
       "num_cylinders          482\n",
       "horsepower             708\n",
       "vehicle_weight           0\n",
       "acceleration           930\n",
       "model_year               0\n",
       "origin                   0\n",
       "fuel_type                0\n",
       "drivetrain               0\n",
       "num_doors              502\n",
       "fuel_efficiency_mpg      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9abc597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   engine_displacement  horsepower  vehicle_weight  model_year  \\\n",
      "0                  170       159.0     3413.433759        2003   \n",
      "1                  130        97.0     3149.664934        2007   \n",
      "2                  170        78.0     3079.038997        2018   \n",
      "3                  220         NaN     2542.392402        2009   \n",
      "4                  210       140.0     3460.870990        2009   \n",
      "\n",
      "   fuel_efficiency_mpg  \n",
      "0            13.231729  \n",
      "1            13.688217  \n",
      "2            14.246341  \n",
      "3            16.912736  \n",
      "4            12.488369  \n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    'engine_displacement',\n",
    "    'horsepower',\n",
    "    'vehicle_weight',\n",
    "    'model_year',\n",
    "    'fuel_efficiency_mpg'\n",
    "]\n",
    "df = df[columns]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ebdfcc",
   "metadata": {},
   "source": [
    "#### Preparing the dataset\n",
    "    Preparation:\n",
    "\n",
    "        Fill missing values with zeros.\n",
    "        Do train/validation/test split with 60%/20%/20% distribution.\n",
    "        Use the train_test_split function and set the random_state parameter to 1.\n",
    "        Use DictVectorizer(sparse=True) to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f720e",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "    Let's train a decision tree regressor to predict the fuel_efficiency_mpg variable.\n",
    "\n",
    "    Train a model with max_depth=1.\n",
    "    Which feature is used for splitting the data?\n",
    "\n",
    "    'vehicle_weight'\n",
    "    'model_year'\n",
    "    'origin'\n",
    "    'fuel_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bfd759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "vehicle_weight    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1) Fill missing values with zeros\n",
    "df = df.fillna(0)\n",
    "\n",
    "# 2) Split the dataset: 60% train, 20% val, 20% test\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "# (0.25 * 0.8 = 0.2 â†’ gives 60/20/20 overall)\n",
    "\n",
    "# 3) Reset index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# 4) Separate target and features\n",
    "y_train = df_train.fuel_efficiency_mpg.values\n",
    "y_val   = df_val.fuel_efficiency_mpg.values\n",
    "y_test  = df_test.fuel_efficiency_mpg.values\n",
    "\n",
    "del df_train['fuel_efficiency_mpg']\n",
    "del df_val['fuel_efficiency_mpg']\n",
    "del df_test['fuel_efficiency_mpg']\n",
    "\n",
    "# 5) Turn dataframes into feature matrices using DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "val_dicts   = df_val.to_dict(orient='records')\n",
    "test_dicts  = df_test.to_dict(orient='records')\n",
    "\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val   = dv.transform(val_dicts)\n",
    "X_test  = dv.transform(test_dicts)\n",
    "\n",
    "# 6) Train DecisionTreeRegressor with max_depth=1\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# 7) Check which feature was used for splitting\n",
    "feature_importances = pd.Series(dt.feature_importances_, index=dv.get_feature_names_out())\n",
    "print(\"Feature importances:\")\n",
    "print(feature_importances[feature_importances > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72fa81f",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "    Train a random forest regressor with these parameters:\n",
    "\n",
    "    n_estimators=10\n",
    "    random_state=1\n",
    "    n_jobs=-1 (optional - to make training faster)\n",
    "    What's the RMSE of this model on the validation data?\n",
    "\n",
    "    0.045\n",
    "    0.45\n",
    "    4.5\n",
    "    45.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d8984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.46\n"
     ]
    }
   ],
   "source": [
    "# Train RandomForestRegressor\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Compute RMSE (manual sqrt to avoid the 'squared' kwarg)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Validation RMSE:\", round(rmse, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275b337",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "    Now let's experiment with the n_estimators parameter\n",
    "\n",
    "    Try different values of this parameter from 10 to 200 with step 10.\n",
    "    Set random_state to 1.\n",
    "    Evaluate the model on the validation dataset.\n",
    "    After which value of n_estimators does RMSE stop improving? Consider 3 decimal places for calculating the answer.\n",
    "\n",
    "    10\n",
    "    25\n",
    "    80\n",
    "    200\n",
    "    If it doesn't stop improving, use the latest iteration number in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da2541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators= 10  ->  RMSE=0.460\n",
      "n_estimators= 20  ->  RMSE=0.454\n",
      "n_estimators= 30  ->  RMSE=0.452\n",
      "n_estimators= 40  ->  RMSE=0.449\n",
      "n_estimators= 50  ->  RMSE=0.447\n",
      "n_estimators= 60  ->  RMSE=0.445\n",
      "n_estimators= 70  ->  RMSE=0.445\n",
      "n_estimators= 80  ->  RMSE=0.445\n",
      "n_estimators= 90  ->  RMSE=0.445\n",
      "n_estimators=100  ->  RMSE=0.445\n",
      "n_estimators=110  ->  RMSE=0.444\n",
      "n_estimators=120  ->  RMSE=0.444\n",
      "n_estimators=130  ->  RMSE=0.444\n",
      "n_estimators=140  ->  RMSE=0.443\n",
      "n_estimators=150  ->  RMSE=0.443\n",
      "n_estimators=160  ->  RMSE=0.443\n",
      "n_estimators=170  ->  RMSE=0.443\n",
      "n_estimators=180  ->  RMSE=0.442\n",
      "n_estimators=190  ->  RMSE=0.442\n",
      "n_estimators=200  ->  RMSE=0.442\n",
      "\n",
      "Best RMSE: 0.442 at n_estimators = 180\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "# Loop over number of trees from 10 to 200 (step 10)\n",
    "for n in range(10, 201, 10):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=n,\n",
    "        random_state=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    scores.append((n, rmse))\n",
    "\n",
    "# Display results\n",
    "for n, s in scores:\n",
    "    print(f\"n_estimators={n:3d}  ->  RMSE={s:.3f}\")\n",
    "\n",
    "# Find where improvement stops\n",
    "best_rmse = min(scores, key=lambda x: x[1])\n",
    "print(\"\\nBest RMSE:\", round(best_rmse[1], 3), \"at n_estimators =\", best_rmse[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29843156",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "    Let's select the best max_depth:\n",
    "\n",
    "    Try different values of max_depth: [10, 15, 20, 25]\n",
    "    For each of these values,\n",
    "    try different values of n_estimators from 10 till 200 (with step 10)\n",
    "    calculate the mean RMSE\n",
    "    Fix the random seed: random_state=1\n",
    "    What's the best max_depth, using the mean RMSE?\n",
    "\n",
    "    10\n",
    "    15\n",
    "    20\n",
    "    25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d452478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=10 -> mean RMSE=0.442\n",
      "max_depth=15 -> mean RMSE=0.445\n",
      "max_depth=20 -> mean RMSE=0.446\n",
      "max_depth=25 -> mean RMSE=0.446\n",
      "\n",
      "Best max_depth: 10 with mean RMSE = 0.442\n"
     ]
    }
   ],
   "source": [
    "depths = [10, 15, 20, 25]\n",
    "results = []\n",
    "\n",
    "for d in depths:\n",
    "    scores = []\n",
    "    for n in range(10, 201, 10):\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=n,\n",
    "            max_depth=d,\n",
    "            random_state=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        scores.append(rmse)\n",
    "    mean_rmse = np.mean(scores)\n",
    "    results.append((d, mean_rmse))\n",
    "    print(f\"max_depth={d:2d} -> mean RMSE={mean_rmse:.3f}\")\n",
    "\n",
    "# Find best depth\n",
    "best = min(results, key=lambda x: x[1])\n",
    "print(\"\\nBest max_depth:\", best[0], \"with mean RMSE =\", round(best[1], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911a814",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "        We can extract feature importance information from tree-based models.\n",
    "\n",
    "        At each step of the decision tree learning algorithm, it finds the best split. When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "        In Scikit-Learn, tree-based models contain this information in the feature_importances_ field.\n",
    "\n",
    "        For this homework question, we'll find the most important feature:\n",
    "\n",
    "        Train the model with these parameters:\n",
    "        n_estimators=10,\n",
    "        max_depth=20,\n",
    "        random_state=1,\n",
    "        n_jobs=-1 (optional)\n",
    "        Get the feature importance information from this model\n",
    "        What's the most important feature (among these 4)?\n",
    "\n",
    "vehicle_weight\n",
    "horsepower\n",
    "acceleration\n",
    "engine_displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebac307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_weight         0.959150\n",
      "horsepower             0.015998\n",
      "acceleration           0.011480\n",
      "engine_displacement    0.003273\n",
      "model_year             0.003212\n",
      "num_cylinders          0.002343\n",
      "num_doors              0.001635\n",
      "origin=USA             0.000540\n",
      "origin=Europe          0.000519\n",
      "origin=Asia            0.000462\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest with the given parameters\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    max_depth=20,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=dv.get_feature_names_out())\n",
    "importances_sorted = importances.sort_values(ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(importances_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201bb46",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Now let's train an XGBoost model! For this question, we'll tune the eta parameter:\n",
    "\n",
    "Install XGBoost\n",
    "Create DMatrix for train and validation\n",
    "Create a watchlist\n",
    "Train a model with these parameters for 100 rounds:\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "Now change eta from 0.3 to 0.1.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "0.3\n",
    "0.1\n",
    "Both give equal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf41fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "122945db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with eta=0.3: 0.45\n",
      "RMSE with eta=0.1: 0.426\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 1) Create DMatrix for train and validation\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "# 2) Train model with eta=0.3\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "model_03 = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=False)\n",
    "y_pred_03 = model_03.predict(dval)\n",
    "rmse_03 = np.sqrt(mean_squared_error(y_val, y_pred_03))\n",
    "print(\"RMSE with eta=0.3:\", round(rmse_03, 3))\n",
    "\n",
    "# 3) Train model with eta=0.1\n",
    "xgb_params['eta'] = 0.1\n",
    "\n",
    "model_01 = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=False)\n",
    "y_pred_01 = model_01.predict(dval)\n",
    "rmse_01 = np.sqrt(mean_squared_error(y_val, y_pred_01))\n",
    "print(\"RMSE with eta=0.1:\", round(rmse_01, 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
